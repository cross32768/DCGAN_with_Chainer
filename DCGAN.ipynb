{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取り敢えずmnistで試す（CPU上での実行を想定しているため）\n",
    "from chainer import Chain, Variable, optimizers, iterators, datasets, training\n",
    "from chainer.training import extensions\n",
    "from chainer.datasets import mnist\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22f00a3cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = mnist.get_mnist(withlabel = False)\n",
    "train = (train - 127.5) / 127.5\n",
    "train = train.reshape(train.shape[0], 28, 28)\n",
    "plt.imshow(train[0], cmap = 'gray')\n",
    "batchsize = 64\n",
    "dis_itr = iterators.SerialIterator(train, batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc1 = L.Linear(100, 1024)\n",
    "            self.fc2 = L.Linear(1024, 128 * 7 * 7)\n",
    "            self.dc3 = L.Deconvolution2D(128, 64, 4, 2, 1)\n",
    "            self.dc4 = L.Deconvolution2D(64, 1, 4, 2, 1)\n",
    "            \n",
    "            self.bn1 = L.BatchNormalization(1024)\n",
    "            self.bn2 = L.BatchNormalization(128 * 7 * 7)\n",
    "            self.bn3 = L.BatchNormalization((64, 14, 14))\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn1(self.fc1(x)))\n",
    "        h = F.relu(self.bn2(self.fc2(h)))\n",
    "        h = F.reshape(h, (h.shape[0], 128, 7, 7))\n",
    "        h = F.relu(self.bn3(self.dc3(h)))\n",
    "        h = F.tanh(self.dc4(h))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.cv1 = L.Convolution2D(1, 64, 5, 2)\n",
    "            self.cv2 = L.Convolution2D(64, 128, 5, 2)\n",
    "            self.fc3 = L.Linear(None, 256)\n",
    "            self.fc4 = L.Linear(256, 1)\n",
    "            \n",
    "            self.bn1 = L.BatchNormalization((64, 12, 12))\n",
    "            self.bn2 = L.BatchNormalization((128, 4, 4))\n",
    "            self.bn3 = L.BatchNormalization(256)\n",
    "    def __call__(self, x):\n",
    "        h = F.leaky_relu(self.bn1(self.cv1(x)), 0.2)\n",
    "        h = F.leaky_relu(self.bn2(self.cv2(h)), 0.2)\n",
    "        h = F.leaky_relu(self.bn3(self.fc3(h)), 0.2)\n",
    "        h = F.dropout(h, 0.5)\n",
    "        h = F.sigmoid(self.fc4(h))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.adam.Adam at 0x22f2fa2c8d0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gen = Generator()\n",
    "model_dis = Discriminator()\n",
    "opt_gen = optimizers.Adam(alpha = 2e-4, beta1 = 0.5)\n",
    "opt_dis = optimizers.Adam(alpha = 2e-4, beta1 = 0.5)\n",
    "opt_gen.setup(model_gen)\n",
    "opt_dis.setup(model_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "\n",
    "GENERATED_IMAGE_PATH = 'generated_images/'\n",
    "if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "    os.mkdir(GENERATED_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    while dis_itr.epoch < max_epoch:\n",
    "        real_images = np.array(dis_itr.next()).reshape(batchsize, 1, 28, 28)\n",
    "        y = model_dis(real_images)\n",
    "        loss = -F.sigmoid_cross_entropy(y.reshape(batchsize,), Variable(np.ones(batchsize).astype(np.int32)))\n",
    "        model_dis.cleargrads()\n",
    "        loss.backward()\n",
    "        opt_dis.update()\n",
    "        \n",
    "        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(batchsize)]).astype(np.float32)\n",
    "        generated_images = model_gen(noise)\n",
    "        y = model_dis(generated_images)\n",
    "        loss = -F.sigmoid_cross_entropy(y.reshape(batchsize,), Variable(np.zeros(batchsize).astype(np.int32)))\n",
    "        model_dis.cleargrads()\n",
    "        loss.backward()\n",
    "        opt_dis.update()\n",
    "        \n",
    "        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(batchsize)]).astype(np.float32)\n",
    "        y = model_dis(model_gen(noise))\n",
    "        loss = -F.sigmoid_cross_entropy(y.reshape(batchsize,), Variable(np.ones(batchsize).astype(np.int32)))\n",
    "        model_gen.cleargrads()\n",
    "        loss.backward()\n",
    "        opt_gen.update()\n",
    "        \n",
    "        if dis_itr.is_new_epoch:\n",
    "            print(\"epoch:\", dis_itr.epoch)\n",
    "            for n,image in enumerate(generated_images):\n",
    "                image = image*127.5 + 127.5\n",
    "                Image.fromarray(image.astype(np.uint8).reshape(SIZE,SIZE,CHANNEL)) \\\n",
    "                                                      .save(GENERATED_IMAGE_PATH+\"%03d_%03d.png\" % (epoch, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[0.49377477],\n",
       "          [0.48071706],\n",
       "          [0.67757636],\n",
       "          [0.07900268],\n",
       "          [0.14918995],\n",
       "          [0.51163566],\n",
       "          [0.20375797],\n",
       "          [0.6071904 ],\n",
       "          [0.50590307],\n",
       "          [0.70900935],\n",
       "          [0.21331999],\n",
       "          [0.8724573 ],\n",
       "          [0.5203341 ],\n",
       "          [0.15140301],\n",
       "          [0.50248003],\n",
       "          [0.6672561 ],\n",
       "          [0.7558276 ],\n",
       "          [0.06742936],\n",
       "          [0.5814702 ],\n",
       "          [0.35230193],\n",
       "          [0.2636234 ],\n",
       "          [0.1104241 ],\n",
       "          [0.65618205],\n",
       "          [0.6456479 ],\n",
       "          [0.17895073],\n",
       "          [0.49548286],\n",
       "          [0.71476763],\n",
       "          [0.68162894],\n",
       "          [0.27497268],\n",
       "          [0.87704116],\n",
       "          [0.46291363],\n",
       "          [0.3266731 ],\n",
       "          [0.4282906 ],\n",
       "          [0.42889568],\n",
       "          [0.48864678],\n",
       "          [0.10695511],\n",
       "          [0.6900749 ],\n",
       "          [0.88779914],\n",
       "          [0.57001734],\n",
       "          [0.55827165],\n",
       "          [0.21440238],\n",
       "          [0.41403753],\n",
       "          [0.5075462 ],\n",
       "          [0.69865644],\n",
       "          [0.6039868 ],\n",
       "          [0.677858  ],\n",
       "          [0.441664  ],\n",
       "          [0.5318151 ],\n",
       "          [0.75480235],\n",
       "          [0.55061096],\n",
       "          [0.5777205 ],\n",
       "          [0.89762187],\n",
       "          [0.61684227],\n",
       "          [0.5413592 ],\n",
       "          [0.5140694 ],\n",
       "          [0.66927296],\n",
       "          [0.5861658 ],\n",
       "          [0.2255643 ],\n",
       "          [0.15729964],\n",
       "          [0.6565795 ],\n",
       "          [0.6878779 ],\n",
       "          [0.6201163 ],\n",
       "          [0.79213667],\n",
       "          [0.32404894]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = mnist.get_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.dataset import concat_examples\n",
    "x, t = concat_examples(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(60000,1,28,28)\n",
    "t.shape\n",
    "t_1 = t[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = model_dis(x[:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable(-1.1475618)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid_cross_entropy(y_1.reshape(32,), t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(batchsize)]).astype(np.float32)\n",
    "generated_images = model_gen(noise)\n",
    "y = model_dis(generated_images)\n",
    "loss = F.sigmoid_cross_entropy(y.reshape(batchsize,), Variable(np.zeros(batchsize).astype(np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.9552179)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
